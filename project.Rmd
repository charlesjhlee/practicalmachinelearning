---
title: "Practical Machine Learning Course Project"
author: "Charles Lee"
date: "24 January 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```

## 0. Preparation  

First, lets load the required libraries and set the random seed for reproducibility.  

```{r, echo = T}
library(caret)
library(xgboost)
library("doParallel")
set.seed(12345)
```

## 1. Executive Summary  

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.  

In this project, the goal is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. This report describes how the model was built, how cross validation was used and what the expected out of sample error is. The final prediction model is used to predict 20 different test cases.  

## 2. Downloading Data  

The following code was used to downlaod the data and to save the training and test files on the local computer.  

```{r}
setwd("/Users/kidstyx/Google Drive/Coursera/practical_machine_learning/project")

trainurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

download.file(trainurl, "training.csv")
download.file(testurl, "testing.csv")

train.source <- read.csv("training.csv", na.strings = c("","NA","#DIV/0!"))
testdata <- read.csv("testing.csv", na.strings = c("","NA","#DIV/0!"))
```

## 2. Data Preprocessing  

The training data was divided into training and validation data in the proportion of 3/4 and 1/4.  

```{r, echo = T}
inTrain <- createDataPartition(train.source$classe, p = 0.75, list = FALSE)
traindata <- train.source[inTrain, ]
validdata <- train.source[-inTrain, ]
```

There were many columns in the dataset that had missing values. The following code is used to remove columns which had more than 50% of the data as missing or as erroneous (#DIV!/0). Furthermore, the first few variables from the data set which were unnecessary for model fitting was removed. These fields were unnecessary as they did not have any predictive power.  

These columns were removed from all of train, validation and test datasets.  

```{r, echo = TRUE}
datamissing <- sapply(traindata, function(x) sum((is.na(x) | x == "")))
badcolumn <- names(datamissing[datamissing > 0.5 * length(traindata$classe)])
notneededcolumn <- c("X","user_name","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","new_window","num_window")

traindata <- traindata[, !(names(traindata) %in% c(badcolumn, notneededcolumn))]
validdata <- validdata[, !(names(testdata) %in% c(badcolumn, notneededcolumn))]
testdata <- testdata[, !(names(validdata) %in% c(badcolumn, notneededcolumn))]
```

Furthremore, the remaining training dataset was checked to see if there were any variables with near zero variances. These variables would not have much predictive power and so could be removed or grouped with a similar variables to try and improve the predictive power. However, the below code showed that there were no near zero variance variables found.  

```{r, echo = TRUE}
nzv <- nearZeroVar(traindata) #no near zero variance features were found.
nzv
```

## 3. Model fitting   

Firstly, multicore was enabled to speed up the fitting process as much as possible and then three models were fitted using the Caret package. These were "xgbTree", "random forest" and "gbm" models suitable for classification problems. Thereafter, predictions were made on the validation data.  

```{r, echo = TRUE}
#use multithreading
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)

fit.xgb <- train(classe~., data = traindata, method = "xgbTree")

fit.rf <- train(classe~., data = traindata, method = "rf")

fit.gbm <- train(classe~., data = traindata, method ="gbm")

#stop multithreading
stopCluster(cl)

pred.xgb <- predict(fit.xgb, newdata = validdata)
pred.rf <- predict(fit.rf, newdata = validdata)
pred.gbm <- predict(fit.gbm, newdata = validdata)
```

##4. Model cross validation and expected out of sample error  

The following confusion matrices were used to test the accuracy of the predictions made using the fitted models on the validation data versus the *classe* variable in the vlidation data.  

```{r, echo = TRUE}
confusionMatrix(pred.xgb, validdata$classe)
confusionMatrix(pred.rf, validdata$classe)
confusionMatrix(pred.gbm, validdata$classe)
```

The results showed that xgboost model had 99.35% accuracy, random forest had 99.29% accuracy and gbm model had 96.11% accuracy.  

Random forest model was chosen as the final model to predict the final 20 cases. Another option could have been to build an ensemble of the xgboost and random forest models but, given that the accuracy of both models are close to 100%, it was decided that random forest model would be used.  

##5. Final predictions on the test data  

The following code was used to make final predictions on the test dataset using the random forest fitted model.  

```{r, echo = T}
pred.final.rf <- predict(fit.rf, newdata = testdata)
pred.final.rf
write.csv(pred.final.rf, "finalsubmit.csv")
```

The final predictions scored 20/20 for the course project prediction quiz.  